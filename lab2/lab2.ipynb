{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that we are utilizing a DL accelerator\n",
    "DEVICE_CPU = torch.device(\"cpu\")\n",
    "DEVICE_GPU = torch.device(\"cuda\")\n",
    "\n",
    "device = DEVICE_GPU if torch.cuda.is_available() else DEVICE_CPU\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "train_set = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=ToTensor())\n",
    "train_set, valid_set = torch.utils.data.random_split(train_set, [0.9, 0.1])\n",
    "\n",
    "labels_map = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\",\n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\",\n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\",\n",
    "}\n",
    "\n",
    "# Plot some images with labels\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n",
    "    img, label = train_set[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.permute(1, 2, 0).squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "# Define model\n",
    "# TODO: Check how the initialization is handled in Pytorch\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=(5, 5), stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5, 5), stride=1)\n",
    "\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.avgpool2 = nn.AvgPool2d(kernel_size=(2, 2), stride=2)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_features=5 * 5 * 16, out_features=120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=120, out_features=84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.avgpool1(self.conv1(X)))\n",
    "        X = F.relu(self.avgpool2(self.conv2(X)))\n",
    "\n",
    "        X = torch.flatten(X, 1)\n",
    "        X = self.mlp(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define train loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    criterion,\n",
    "    dataloaders: DataLoader,\n",
    "    n_epochs: int,\n",
    "    device=DEVICE_GPU,\n",
    "):\n",
    "    model.to(device)\n",
    "\n",
    "    best_acc, best_model_wts = 0.0, deepcopy(model.state_dict())\n",
    "\n",
    "    for _ in (pbar := trange(1, n_epochs + 1)):\n",
    "        for phase in [\"train\", \"valid\"]:\n",
    "            if phase == \"train\":\n",
    "                # Set model to training mode\n",
    "                model.train()\n",
    "            else:\n",
    "                # Set model to evaluate mode\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    # Get model outputs and calculate loss\n",
    "\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    preds = torch.argmax(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.float() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == \"valid\" and epoch_acc > best_acc:\n",
    "                best_acc, best_model_wts = epoch_acc, deepcopy(model.state_dict())\n",
    "\n",
    "        pbar.set_description(f\"Best valid acc {best_acc*100:.2f}%\")\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model: nn.Module, dataloader: DataLoader, device=DEVICE_GPU):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    corrects = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = torch.argmax(outputs, 1)\n",
    "        corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    test_acc = corrects / len(dataloader.dataset)\n",
    "    # print(f\"Test Acc: {test_acc:.4f}\")\n",
    "    return test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# Define data loaders\n",
    "dataloaders = {\n",
    "    \"train\": DataLoader(train_set, batch_size=batch_size, shuffle=True),\n",
    "    \"valid\": DataLoader(valid_set, batch_size=batch_size, shuffle=True),\n",
    "}\n",
    "\n",
    "# Define model, loss function and optimizer (with defaul params)\n",
    "model = LeNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters())\n",
    "\n",
    "# Train model\n",
    "train_model(model, optimizer, criterion, dataloaders, n_epochs=30)\n",
    "\n",
    "# Evaluate model performance\n",
    "test_set = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=ToTensor())\n",
    "test_dataloader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n",
    "eval_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvGroup(nn.Module):\n",
    "    def __init__(self, channels_in: int, channels_out: int, pool: bool = False):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = [\n",
    "            nn.Conv2d(channels_in, channels_out, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(channels_out),\n",
    "            nn.ReLU(),\n",
    "        ]\n",
    "\n",
    "        if pool:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "        self.conv_group = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, X: Tensor):\n",
    "        return self.conv_group(X)\n",
    "\n",
    "\n",
    "class ResNet9(nn.Module):\n",
    "    def __init__(self, p: float = 0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_group1 = ConvGroup(3, 64, pool=False)\n",
    "        self.conv_group2 = ConvGroup(64, 128, pool=True)\n",
    "        self.conv_group3 = ConvGroup(128, 256, pool=True)\n",
    "        self.conv_group4 = ConvGroup(256, 512, pool=True)\n",
    "\n",
    "        self.res1 = nn.Sequential(ConvGroup(128, 128), ConvGroup(128, 128))\n",
    "        self.res2 = nn.Sequential(ConvGroup(512, 512), ConvGroup(512, 512))\n",
    "\n",
    "        self.dropout1 = nn.Dropout(p)\n",
    "        self.dropout2 = nn.Dropout(p)\n",
    "\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=4),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=512, out_features=10),\n",
    "        )\n",
    "\n",
    "    def forward(self, X: Tensor):\n",
    "        y = X\n",
    "\n",
    "        y = self.conv_group1(y)\n",
    "        y = self.conv_group2(y)\n",
    "        y = y + self.res1(y)\n",
    "\n",
    "        y = self.conv_group3(y)\n",
    "        y = self.conv_group4(y)\n",
    "        y = y + self.res2(y)\n",
    "\n",
    "        y = self.dropout2(y)\n",
    "\n",
    "        y = self.clf(y)\n",
    "\n",
    "        return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
